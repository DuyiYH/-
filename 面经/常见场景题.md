# 交集问题
1. 要看两个集合占用内存多少，如果不是特别大，直接进内存。
2. 如果比较大，还是需要分治的，然后用hash进行分治
3. 最后用hashSet来查重
## 十亿个数的集合和10w个数的集合，如何求它们的交集。
只对小数组进行处理(因为10W个数，占内存不到1M，可以接受)，对小数组做hashMap存放，然后遍历大数组即可(这边的话，，10亿个数，如果是int的话，大概是4G内存，可能需要对10亿个数进行切分。可以根据主机情况，开多线程，例如16核cpu开16个线程，怎么划分十亿个数的话，hashcode % 16取余)。时间复杂度是O(N),空间复杂度就是O(n);
## 两个文件共同的url，即AB两个文件里的交集
题意：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4GB。找出a、b文件共同的url
解答：
1. 先估计每个文件的大小，50亿个URL且每个URL大小为64字节，则需要5G*64=320G > > 4G的内存，所以肯定要分治.
2. 分治，320G / 4G = 80，所以最少要分80个文件件，然后这边的话，可以分得更小些，例如对url求取hash(url) % 1024 或者 160(最小细分值)这样子，将文件分成了300Mb，或者是2G这样子。
> **为什么要hash** ： 每个文件中可能包含相同的url，同一文件中相同的url可能分布在同一文件的不同位置。不同文件中相同的url可能也分布在不同位置。hash可以保证相同url映射到同一个小文件中
3. 同理，对b文件也进行细分成相同数量的小文件，这个时候AB文件中所有可能相同的url就都存在于[A0][B0] A[1]B[1]。然后相同的url应该就不会在不同的文件中了(**hash的作用**)。
4. 然后依次遍历1024对文件，其中一个存在hashset，另一个用来遍历。


# Top K大问题 (在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数)
-   针对top K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆（就是上面提到的最小堆），即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树或者Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K。
## 十亿个数找到前100个最大的，堆排序，怎么实现，怎么调整。
https://bbs.csdn.net/topics/360043630
解答1：因为只有前100个最大数，所以可以直接用堆排序，采用小顶堆，十亿个数的话，如果是int，可能得4G内存，如果内存不够，可以用hash取余来细分。建堆时间复杂度是O（mlogm），算法的时间复杂度为O（nmlogm）（n为10亿，m为10000）
解答1优化版本(空间换时间)：可以把所有10亿个数据分组存放，比如分别放在1000个文件中。这样处理就可以分别在每个文件的10^6个数据中找出最大的10000个数，合并到一起在再找出最终的结果。时间复杂度就小了，因为n从10亿到了100万，然后空间多了，因为多了1000个堆。
解答2：如果是int型的无符号数的话，可以采用分别统计高低位的思想。
设一个计数器数组  Count[65536]
第一次扫描：  Count[A[i] >> 16] ++。  以数字的高16位作为下标，直接对计数器 + 1。
如此一来可以统计出各个高16位的个数。对计数器从高到低进行一遍扫描，并进行累加就可以得出排在第10万的数字它的高16位是多少，设为H。然后也能知道这个最小的高16位数，有多少个数N，问题就变成了低16位里面寻找第N大。

计数器全部清0，并进行第二次扫描。 若 a[i] 的高16位大于H，则该数字肯定是最大的10万个里面的，也不需要管。若a[i]的高16位小于H，则直接忽略。若等于H， 则将其低 16位作为下标对计数器+1. 即：Count[a[i] & 0xFFFF] ++。
第二次扫描结束后， 看看还缺多少个数字， 对计数器也再做一次 从高到低的扫描，直接根据 高16位的H 以及计数器的低16位构造即可。
## 100w个数，怎么找到前1000个最大的，堆排序，怎么构造，怎么调整，时间复杂度。
## 找出文件中频率最高的100个词(有一个1GB大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1MB。返回频数最高的100个词)
1GB文件，一个词16字节，则一共有2^30 / 2 ^ 4 = 2 ^ 26 大概6000W个词
因为内存只有1MB，所以首先需要切分，切分一般采用hash取余，可以直接对5000取余，这样子基本上每个文件都为200kb，如果有文件大于1MB的话，就继续取余(看文件大小)，如果都是一个词，取余两次也就判断出来了。

对每一个文件，都能放到内存里，所以就可以用hashmap来统计频率了，然后每个文件里都可以纪录频率最大的100个数
然后开始进行合并，可以采用多路归并的方式(用堆 or 胜者树/败者树)

# 中位数问题
## 100亿个整数的中位数
**内存足够情况下**
100亿个int数，大概是40G内存吧，10亿是1G.如果内存足够的话，可以直接放进来比较
1. 采用快排的partition
• 随机选取一个数，将比它小的元素放在它左边，比它大的元素放在右边
• 如果它恰好在中位数的位置，那么它就是中位数，直接返回
• 如果小于它的数超过一半，那么中位数一定在左半边，递归到左边处理（还是第几大）
• 否则中位数一定在右半边，根据左半边的元素个数计算出中位数是右半边的第几大（重新算第几大），然后递归到右半边处理
**内存不够的情况下(看数量)**
1. partition快排的思想，只不过这个mid只能选范围中值了，int的取值范围是-2^31, 2^31-1(20亿)，无符号数的话0，2^32(40亿)，取这个范围中指数
因为是整数，所以可以知道范围，然后选一个中间值，然后遍历，得出有个数< mid，多少个数>mid, 多少个数=mid，根据结果可以进一步调整mid情况然后递归找到中位数。
2. 分桶
将这么大的数给细分，把所有数划分到各个小区间（称作“桶”），把每个数映射到对应的区间里（具体的划分可以根据高位情况来，比如以整数的最高5位作为桶的下标，桶的范围就是11111-00000），统计每个区间中数的个数。数一遍各个区间，看中位数落在哪个区间。如果中位数所在的区间能够一次载入内存，那么载入内存查找。否则，继续将这个区间进行划分，直到中位数所在的区间能一次载入内存为止.

# 位图 bitmap(位图(Bit-map)的原理就是使用位数组来表示某些元素是否存在，由于采用了bit为单位来存储数据，因此在存储空间方面，可以大大节省，故适用于海量数据的快速查找、判断、删除等)
## 11实现位图(怎么去设置1和减去1的，如何从数定位到数组索引到里面具体的那一位)
例子一(引入)：假设数值范围是[ 0,7]，有5个元素(4,7,2,5,3)。需要对这5个元素排序
如果使用位图来排序，总共需要8位(**需要明确范围**)，因为0~7一共8个数字，处理步骤如下：
    设置位图状态：遍历数组，如果包含0~7中某个元素，则设置位图8个位中相应的位为1
    遍历位图，输出结果：遍历位图，输出排序结果
例子二：假设有100亿个数(10,000,000,000)，如果使用int(4字节)数组实现位图，每个int可以表示32个数，那么可以使用100亿/8，大约1GB左右的空间就能存下所有100亿个数
**注意点：** 由于位图每位只有0和1，所以只能表示1个元素是否存在，如果数组包含相同元素，位图没有办法记录。位图很适合在海量数值中查找某个数值是否存在。如果希望用位图记录一个数字是否多次出现，可以用2bit位图（00不存在，01存在，10出现多次，11无意义）
## 统计不同号码的个数
一般号码都是8位的短号和11位的手机号，8位的短号。范围是[0,99999999], 用位图解决的话，只需要开一个1200W的空间，大概12MB，遍历号码，将对应位置设为1，然后统计位图中1的个数，即为不同号码的个数
## 查找某个数是否在40亿个数当中(给40亿个不重复的unsigned int的整数，没排过序，然后再给一个数，如何快速判断这个数是否在40亿个数当中？)
无符号数的话，从0,2^32-1,范围明确，40亿个数差不多也正好是2^32次，开位图的话，500M大小空间就可以完成。对40亿个数，遍历一次，位图对应位置处赋值位1，然后再去判断给的那个数的对应bit位是否为1，如果为1，就存在，不为1就不存在。
## 2.5亿整数只出现一次的整数(在2.5亿个整数中找出只出现一次的整数(其他出现次数不定)，内存不足以容纳这2.5亿个整数)
1. 采用2bit位图（每个数分配2bit，**00表示不存在，01表示出现一次，10表示多次，11无意义**），共需内存(2^32)*2bit=1GB内存，然后依次扫描2.5亿个整数，查看Bitmap中对应位，如果是00则变为01，01变为10，10保持不变。扫描结束后，查看bitmap，把对应位是01的整数输出
2. 采用Hash映射的方法，划分成多个小文件(hashcode取余)。然后在小文件中利用hash_map找出不重复的整数
## 2.5亿整数唯一出现两次的数
思路一样的
1. 采用2bit位图（每个数分配2bit，**00表示不存在，01表示出现一次，10表示多次，11无意义**），共需内存(2^32)*2bit=1GB内存，然后依次扫描2.5亿个整数，查看Bitmap中对应位，如果是00则变为01，01变为10，10保持不变。扫描结束后，查看bitmap，把对应位是10的整数输出
2. 采用Hash映射的方法，划分成多个小文件(hashcode取余)。然后在小文件(内存放得下就行)中利用hash_map找出重复的整数

# 其他
## 布隆过滤器(位图的扩展)
布隆过滤器可视为对位图的扩展，如果需要判断一个元素是否在一个集合中，位图的做法是申请一个N位（N为集合中最大整数）的数组，然后每一位对应一个特定整数，布隆过滤器可以让开的数组空间小一些，通过多个hash来实现。布隆过滤器的位数m通常要比集合中的最大元素小的多，可见，布隆过滤器是一种空间效率和时间效率很高的随机数据结构。
1. 插入：当向集合中插入一个元素时，根据k个Hash函数可以得到位数组中的k个位，将这些位全部设置为1
2. 查询：当要查询某个元素是否属于集合时，就使用k个哈希函数得到此元素对应的k个位，如果所有点都是1，那么判断为元素在集合内（注意，这种情况下只能说明元素可能在集合内，并不一定），如果有0，则元素不在集合内（因此，其实布隆过滤器的思想是“宁可误杀也不放过”，适用于黑名单网站的查询）

**缺点** (误判率 + 只能插入和查询， 修改和删除做不到)
在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合。因此，布隆过滤器不适合那些“零错误”应用场合，而在能容忍低错误率的应用场合下，布隆过滤器通过极少的错误换取了存储空间的极大节省
## 倒排索引法(反向索引、置入档案、反向档案) (反向索引则是单词指向了包含它的文档,正向索引是指文档包含了哪些单词)
用来存储在全文检索下某个单词在一个文档或者一组文档中的存储位置的映射。**是文档检索系统中最常用的数据结构**，**搜索引擎的关键字查询**
    T0 = "it is what it is"
    T1 = "what is it"
    T2 = "it is a banana"
可以得到反向文件索引
    "a"：{2}
    "banana"：{2}
    "is"：{0,1,2}
    "it"：{0,1,2}
    "what"：{0,1}
如果当用户检索的条件为"what"、"is"和"it"时，将分别查询这三个关键词对应的文本集合，然后求对应集合的交集。可见，倒排索引在处理复杂的多关键字查询时，可在倒排表中先完成查询的并、交等逻辑运算，得到结果后再对记录进行存取
## 败者树 胜者树(与最值查找有关)
胜者树和败者树都是完全二叉树，是树形选择排序的一种变型。每个叶子结点相当于一个选手，每个中间结点相当于一场比赛，每一层相当于一轮比赛。
不同的是，胜者树的中间结点记录的是胜者的标号；而败者树的中间结点记录的败者的标号。
**胜者树与败者树可以在log(n)的时间内找到最值**。任何一个叶子结点的值改变后，利用中间结点的信息，还是能够快速地找到最值。在k路归并排序中经常用到。
![](image/败者树.png)
叶子节点相当于参赛选手，中间节点是比赛，比赛中败者记录在中间节点，胜者继续参加后面的比赛，直到根节点。根节点之上的一个节点用来记录最终胜者。

**败者树的建立**：在参赛者数组b[]的最后添加一位，存放一个参赛选手的绝对最小值（选手都是正数的话，如-1）。所有中间节点都记录这个最小值的下标。然后依次调整（adjust()）各个选手即可。
**败者树的调整**：当改变一个选手的值，需要调整以维持败者树的形态。败者树只需调整选手的父节点即可。当子节点的值大于父节点，则子节点记录于父节点（小为胜利，记录败者），父节点继续与其父节点比赛；若子节点小于父节点，则直接使用子节点进行下一轮比赛。

**败者树的应用**
败者树常常用于多路外部排序，对于K个已经排好序的文件，将其归并为一个有序文件。败者树的叶子节点是数据节点，两两分组，内部节点记录左右子树中的“败者”，优胜者往上传递一直到根节点，如果规定优胜者是两个数中的较小者，则根节点记录的是最后一次比较中的败者，也就是第二小的数，而用一个变量来记录最小的数。把最小值输出以后，用一个新的值替换最小值节点的值（在文件归并的时候，如果文件已经读完，可以用一个无穷大的数来替换），接下来维护败者树，从更新的节点往上，一次与父节点比较，将败者更新，胜者继续比较。

**败者树和堆的比较**
昨晚睡觉之前，还在想堆和败者树到底哪一个更优的题目。终极通过心算得出答案（感爱好的人可以算一下，并不难）：假如将N个数的分布看作是完全随机分布，则通过求和可以计算出，当从N个数中提取出一个新的数m时，假如该数比之前找到的n个最大的数中的最小的x大，则会替换x进进“堆”或者“败者树”。

在这一次重新维护堆和败者树的时候，**堆的期待比较次数是2logn-1，而败者树是logn**。但是由于败者树内部节点存放的是叶子节点的下标，在进行比较的时候需要间接取值（先访问内部节点得到下标，在用此下标取到叶子节点中存放的数），所以比较时**败者树访问内存次数是堆的两倍**。

而在交换次数上（堆是父节点和子节点交换，败者树是往上走的优越者和内部节点存放的败者进行交换，每次交换需要三次操纵），**堆的交换次数期看值是1/2logn-1/4，而败者树是1/2logn**（这里全都忽略了logn的取整题目）。

我不能确定**到底一次比较和一次内存访问到底哪一个更快**，我猜想是内存访问更快，那样的话，败者树的比较性能会比堆更优。而在交换方面，到底那1/4的差会有多大影响，我也不好说了。

败者树在维护的时候，比较次数是logn+1,  败者树从下往上维护，每上一层，只需要和父节点比较一次，而堆是自上往下维护，每一层需要和左右子节点都比较，需要比较两次，从这个角度，败者树比堆更优一点，但是，败者树每一次维护，必然是从叶子节点到根节点的一条路径，而堆维护的时候有可能在中间某个层次停止，这样败者树虽然每层比堆比较的次数少，但是堆比较的层数可能比较少。

## 一个矩阵，从左上角到右下角，每个位置有一个权值。可以上下左右走，到达右下角的路径权值最小怎么走。
leetcode里有原题，就是路径权值问题，dp可做
## 四辆小车，每辆车加满油可以走一公里，问怎么能让一辆小车走最远。说了好几种方案，面试官引导我优化了一下，但是还是不满意，最后他说跳过。

# 图，并查集，字典树
## 朋友之间的点对点关系用图维护，怎么判断两人是否是朋友，并查集，时间复杂度，过程。没讲清楚
## 如何实现关键字输入提示，使用字典树，复杂度多少，有没有其他方案，答哈希，如果是中文呢，分词后建立字典树？
## 代码中遇到进程阻塞，进程僵死，内存泄漏等情况怎么排查。通过ps查询状态，分析dump文件等方式排查。
## 10g文件，只有2g内存，怎么查找文件中指定的字符串出现位置。MapReduce分割文件处理。
他说可以用cat | grep 管道处理。
## 2.5亿个数，只有一个数出现两次，其余都只出现了一次，怎么去找出那个数

## 对大量数据取前10大（讲了长度为10的堆排序、桶、基数以及时间fu复杂度），感觉不该说桶和基数的，计算读10遍复杂度也更低。但我觉得堆排序是最完美了，但是面试官并不满意，也可能我太慌了，没说清楚。
## nlgn的算法有什么相同点？表示不大清楚堆排序和其他有什么区别，其他俩都是分而治之，而且没有重叠。
## 1到100的和写出能想到的所有算法（写了等差求和、循环和递归实现）
## 10亿个数怎么排序，口述思路（说了多路归并加堆，堆优化成败者树也行，还好没问败者树的原理）
## 有5000w行数据，要怎么快速查询？
## 非递归快排 
## 怎么实现网络聊天室
## 设计一个分布式全局唯一id，如果要自增怎么办
## 把十进制数转成n进制
## (概率题)把一根绳子切成三段，能够组成一个三角形的概率是多少？
## 如何设计一个秒杀系统？
## 深拷贝（循环引用、多种类型）
## 实现LFU 最不经常使用的实现
## n进制转m进制
## rand2到randn
## 11合并k个链表
我用的是合并两个链表，然后使用分治合并k个链表 面试官认为我这个算法不太好，有更好的优化方式，接着提出了hashMap，让联想一下hashMap来讲解题思路 一次性并行的比较k个链表进行合成是更快的，