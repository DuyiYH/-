# 数据结构

<https://www.jianshu.com/p/230e6fde9c75>

## **堆**

### 大根树/小根树

- 每个节点的值都大于（或小于）等于其子节点

### **大根堆/小根堆**

- 一个大根堆/小根堆既是大根树（小根树）也是完全二叉树

### **大根堆的插入**

1. 将新元素插入新节点
2. 沿着新节点到根节点的路径，执行起泡操作，将新元素与其父节点的元素比较交换，知道后者大于等于前者为止

```c++
/********************************************
 * 向堆中插入元素
 *  hole：新元素所在的位置
 ********************************************/
template <class value>
void _push_heap(vector<value> &arr,int hole){
    value v = arr[hole]; //取出新元素，从而产生一个空洞
    int parent = (hole - 1) / 2;
    //建最大堆，如果建最小堆换成 arr[parent] > value
    while(hole > 0 && arr[parent] < v){
        arr[hole] = arr[parent];
        hole = parent;
        parent = (hole - 1) / 2;
    }
    arr[hole] = v;
}
```

### **大根堆的删除**

删除实际上是将堆顶元素移入数组末尾，并不是真的删除。删除节点时，进行下列操作：

1. 保存数组末尾元素(存如临时变量`v`)，将堆顶元素存入数组末尾
2. 将原来堆顶元素的两个子节点中较大的一个移入堆顶(以最大堆为例)，填补空缺，此时产生新的空缺，继续此步骤，直到空缺为一个叶子节点
3. 将`v`中存储的值移到空缺叶子节点的位置
4. 对上一步中的新叶子节点完成向上比较交换操作

```c++
/********************************************
 * 删除堆顶元素
 ********************************************/
template <class value>
void _pop_heap(vector<value> &arr,int sz)
{
    value v = arr[sz - 1];
    arr[sz - 1] = arr[0];
    --sz;
    int hole = 0;
    int child = 2 * (hole + 1); //右孩子
    while(child < sz){
        if(arr[child] < arr[child - 1])
            --child;
        arr[hole] = arr[child];
        hole = child;
        child = 2 * (hole + 1);
    }
    if(child == sz){
        arr[hole] = arr[child - 1];
        hole = child - 1;
    }
    arr[hole] = v;
    _push_heap(arr,hole);
}
```

### 建堆

- **堆的大小固定(且所有元素已知)**：按“序号从大到小”的顺序遍历所有非叶子节点，将这些节点与左右子节点较大者(以最大堆为例)交换，执行siftdown一直到叶子节点，因此，每遍历到一个节点时，其左子树和右子树都已经是最大堆，只需对当前节点执行siftdown操作
- **堆的大小未知(如数据流)**：可以通过插入操作来构建堆

```c++
/********************************************
 * 建堆
 *  sz：删除堆顶元素后的大小
 *  v： 被堆顶元素占据的位置原来的元素的值
 ********************************************/
template <class value>
void _make_heap(vector<value> &arr)
{
    int sz = arr.size();
    int parent = (sz - 2) / 2;
    while(parent >= 0){
        int hole = parent;
        int child = 2 * (hole + 1); //右孩子
        value v = arr[hole];
        while(child < sz){
            if(arr[child] < arr[child - 1])
                --child;
            arr[hole] = arr[child];
            hole = child;
            child = 2 * (hole + 1);
        }
        if(child == sz){
            arr[hole] = arr[child - 1];
            hole = child - 1;
        }
        arr[hole] = v;
        _push_heap(arr,hole);
        --parent;
    }
}
```

### 复杂度

- **插入节点**：时间复杂度为O(logn)
- **删除堆顶**：时间复杂度为O(logn)
- **建堆**：
  - **堆的大小固定(且所有元素已知)**：每个siftdown操作的最大代价是节点被向下移动到树底的层数。在任意一棵完全二叉树中，大约有一半的节点是叶节点，因此不需要向下移动。四分之一的节点在叶节点的上一层，这样的节点最多只需要移动一层。每向上一层，节点的数目就为前一层的一般，而子树高度加1，因此移动层数加一。**时间复杂度为O(n)**
  - **堆的大小未知(如数据流)**：由于插入节点的时间代价为O(logn)，对于n个元素，每个执行一次插入操作，所以**时间复杂度为O(nlogn)**

## 搜索树

### 二叉查找树 (Binary Search Tree)

概念
二叉查找树又称二叉搜索树，二叉排序树，特点如下:

1. 左子树上所有结点值均小于根结点
2. 右子树上所有结点值均大于根结点
3. 结点的左右子树本身又是一颗二叉查找树
4. 二叉查找树中序遍历得到结果是递增排序的结点序列。

BST 的操作代价分析：
(1) 查找代价：
任何一个数据的查找过程都需要从根结点出发，沿某一个路径朝叶子结点前进。因此查找中数据比较次数与树的形态密切相关。
当树中每个结点左右子树高度大致相同时，树高为logN。则平均查找长度与logN成正比，查找的平均时间复杂度在O(logN)数量级上。
当先后插入的关键字有序时，BST退化成单支树结构。此时树高n。平均查找长度为(n+1)/2，查找的平均时间复杂度在O(N)数量级上。

(2) 插入代价：
新结点插入到树的叶子上，完全不需要改变树中原有结点的组织结构。插入一个结点的代价与查找一个不存在的数据的代价完全相同。

(3) 删除代价：
当删除一个结点P，首先需要定位到这个结点P，这个过程需要一个查找的代价。然后稍微改变一下树的形态。如果被删除结点的左、右子树只有一个存在，则改变形态的代价仅为O(1)。如果被删除结点的左、右子树均存在，只需要将当P的左孩子的右孩子的右孩子的…的右叶子结点与P互换，在改变一些左右子树即可。因此删除操作的时间复杂度最大不会超过O(logN)。

BST效率总结 :
查找最好时间复杂度O(logN)，最坏时间复杂度O(N)。

原文链接：<https://blog.csdn.net/z702143700/article/details/49079107>

### 平衡二叉查找树 ( Balanced Binary Search Tree )

二叉查找树在最差情况下竟然和顺序查找效率相当，这是无法仍受的。事实也证明，当存储数据足够大的时候，树的结构对某些关键字的查找效率影响很大。当然，造成这种情况的主要原因就是BST不够平衡(左右子树高度差太大)。既然如此，那么我们就需要通过一定的算法，将不平衡树改变成平衡树。因此，AVL树就诞生了。

AVL 的操作代价分析：
(1) 查找代价：
AVL是严格平衡的BST（平衡因子不超过1）。那么查找过程与BST一样，只是AVL不会出现最差情况的BST(单支树)。因此查找效率最好，最坏情况都是O(logN)数量级的。

(2) 插入代价：
AVL必须要保证严格平衡(|bf|<=1)，那么每一次插入数据使得AVL中某些结点的平衡因子超过1就必须进行旋转操作。事实上，AVL的每一次插入结点操作最多只需要旋转1次(单旋转或双旋转)。因此，总体上插入操作的代价仍然在O(logN)级别上(插入结点需要首先查找插入的位置)。

(3) 删除代价：
AVL删除结点的算法可以参见BST的删除结点，但是删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。因此删除的代价稍微要大一些。每一次删除操作最多需要O(logN)次旋转。因此，删除操作的时间复杂度为O(logN)+O(logN)=O(2logN)

AVL 效率总结 :
查找的时间复杂度维持在O(logN)，不会出现最差情况
AVL树在执行每个插入操作时最多需要1次旋转，其时间复杂度在O(logN)左右。
AVL树在执行删除时代价稍大，执行每个删除操作的时间复杂度需要O(2logN)。

## **红黑树**

### **红黑树的性质**

1. 根节点和外部节点都是黑色
2. 没有两个连续节点是红色
3. 在所有跟至外部节点的路径上，黑色节点的数目相同
4. 令h为一棵红黑树的高度，n是内部节点数量，r是根节点的阶则

    1. h <= 2r
    2. n >=2^r -1
5. 能保证在最坏情况下，基本的动态几何操作的时间均为O（lgn）

### **红黑树的插入**

- <https://blog.csdn.net/vicky_cr/article/details/105460774?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_utm_term-0&spm=1001.2101.3001.4242>

### **红黑树相比于BST和AVL树有什么优点？**

- 红黑树是牺牲了严格的高度平衡的优越条件为代价，它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。红黑树能够以O(log2 n)的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。当然，还有一些更好的，但实现起来更复杂的数据结构能够做到一步旋转之内达到平衡，但红黑树能够给我们一个比较“便宜”的解决方案。

### **红黑树解决了什么问题**

- 解决了二叉查找树的线性问题;进行平衡性

### **红黑树相对于哈希表，在选择使用的时候有什么依据？**

- 权衡三个因素: 查找速度, 数据量, 内存使用，可扩展性。
- 总体来说，hash查找速度会比map快，而且查找速度基本和数据量大小无关，属于常数级别;而map的查找速度是log(n)级别。并不一定常数就比log(n) 小，hash还有hash函数的耗时，明白了吧，如果你考虑效率，特别是在元素达到一定数量级时，考虑考虑hash。但若你对内存使用特别严格， 希望程序尽可能少消耗内存，那么一定要小心，hash可能会让你陷入尴尬，特别是当你的hash对象特别多时，你就更无法控制了，而且 hash的构造速度较慢。
- 红黑树并不适应所有应用树的领域。如果数据基本上是静态的，那么让他们待在他们能够插入，并且不影响平衡的地方会具有更好的性能。如果数据完全是静态的，例如，做一个哈希表，性能可能会更好一些。
- 在实际的系统中，例如，需要使用动态规则的防火墙系统，使用红黑树而不是散列表被实践证明具有更好的伸缩性。Linux内核在管理vm_area_struct时就是采用了红黑树来维护内存块的。
- 红黑树通过扩展节点域可以在不改变时间复杂度的情况下得到结点的秩。

## **B-（B）树**

### **概念**

1. 是一种多路搜索树，而非二叉，设为M阶
2. 每个节点关键字个数 = 最大儿子数 - 1
3. 每个节点至少存放M/2-1（取上整）和至多M-1个关键字
4. 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] < K[i+1]；
5. 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树；
6. 所有叶子结点位于同一层；

### **B-树的搜索**

- 从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点；

### **B-树特性**

1. 关键字集合分布在整颗树中；
2. 任何一个关键字出现且只出现在一个结点中；
3. 搜索有可能在非叶子结点结束；
4. 其搜索性能等价于在关键字全集内做一次二分查找；
5. 自动层次控制；

## **B+树**

### **概念**

1. 其定义基本与B-树同，除了：
2. 非叶子结点的子树指针与关键字个数相同；
3. 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）；
4. 为所有叶子结点增加一个链指针；
5. 所有关键字都在叶子结点出现；

### **B+树搜索**

- B+的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找；

### **B+树特性**

1. 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的；
2. 不可能在非叶子结点命中；
3. 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；
4. 更适合文件索引系统；

## **B-树（B-）与B+树的不同**

1. M阶B-有M-1个关键字，M个子树；而M阶B+树最多M个关键字与M个子树
2. B-树所有关键字分布在整个树中，查找时可能会在非叶子节点结束；B+树所有关键字都出现在叶子结点的链表中，查找时必定在叶子节点结束

### **B-B+的插入删除**

1. 插入

- 找到应当包含记录的**叶节点L**
  - 如果L没满：将新纪录添加进去
  - 如果L已满：将其分裂成2个节点（在两个节点之间平均分配记录），然后在新形成的右边节点把最小关键码值的一份副本提升到父节点。这个提升过程可能会一直进行到根节点，引起根节点分裂，从而增加一层

2. 删除
    1. 如果叶节点超过半满：
        - 只需清除记录R，剩下的叶节点L仍然至少半满（**下图1**）
    2. 如果叶节点没有半满，查看相邻的兄弟节点（节点下溢）：
        - 兄弟节点的记录很多：从兄弟节点获取元素，使两个节点有同样多的记录（这样做是为了尽可能延迟由于删除而引起的节点再次下溢）（**下图2**）
        - 如果没有一个兄弟节点可以把记录借出来，则将叶节点与一个兄弟节点合并（**下图3**）。可能会依次使父节点下溢，如果根节点的最后两个子女合并到一起，那么树就会减少一层

### B+ B-树常用场景

文件系统和数据库系统中常用的B/B+ 树，他通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少IO操作。他广泛用于文件系统及数据库中，如：

Windows：HPFS 文件系统
Mac：HFS，HFS+ 文件系统
Linux：ResiserFS，XFS，Ext3FS，JFS 文件系统
数据库：ORACLE，MYSQL，SQLSERVER 等中

## 动态查找树结构的对比：

### 堆和树的区别

1. 堆并不一定是完全二叉树，平时使用完全二叉树的原因是易于存储，并且便于索引。所有父结点都比子结点要小的完全二叉树我们称为最小堆。反之，如果所有父结点都比子结点要大，这样的完全二叉树称为最大堆。
2. 大部分时间我们是使用完全二叉树来存储堆的，但是堆并不等于完全二叉树，例如二项堆，斐波那契堆，就不属于二叉树。
3. 树是什么
   只要无环无向联通图都叫树，具体就是n个点n-1条无向边连接且任意两点联通的一种拓扑结构

### 平衡二叉树和红黑树 [AVL PK RBT]
AVL 和RBT 都是二叉查找树的优化。其性能要远远好于二叉查找树。他们之间都有自己的优势，其应用上也有不同。
结构对比： AVL的结构高度平衡，RBT的结构基本平衡。平衡度AVL > RBT.
查找对比： AVL 查找时间复杂度最好，最坏情况都是O(logN)。RBT 查找时间复杂度最好为O(logN)，最坏情况下比AVL略差。
插入删除对比：

1. AVL的插入和删除结点很容易造成树结构的不平衡，而RBT的平衡度要求较低。因此在大量数据插入的情况下，RBT需要通过旋转变色操作来重新达到平衡的频度要小于AVL。
2. 如果需要平衡处理时，RBT比AVL多一种变色操作，而且变色的时间复杂度在O(logN)数量级上。但是由于操作简单，所以在实践中这种变色仍然是非常快速的。
3. 当插入一个结点都引起了树的不平衡，AVL和RBT都最多需要2次旋转操作。但删除一个结点引起不平衡后，AVL最多需要logN 次旋转操作，而RBT最多只需要3次。因此两者插入一个结点的代价差不多，但删除一个结点的代价RBT要低一些。
4. AVL和RBT的插入删除代价主要还是消耗在查找待操作的结点上。因此时间复杂度基本上都是与O(logN) 成正比的。
总体评价：大量数据实践证明，RBT的总体统计性能要好于平衡二叉树。

### B-树和B+树 [ B-Tree PK B+Tree]

B+树是B-树的一种变体，在磁盘查找结构中，B+树更适合文件系统的磁盘存储结构。
结构对比：
B-树是平衡多路查找树，所有结点中都包含了待查关键字的有效信息(比如文件磁盘指针)。每个结点若有n个关键字，则有n+1个指向其他结点的指针。

B+树相比B-树的特点：

1. 数据只出现在叶子结点，B-树每个结点都包含了数据；
2. 叶子结点之间用指针连接；
3. B+树的高度一般是3；

查找对比：
1. 在相同数量的待查数据下，B+树查找过程中需要调用的磁盘IO操作要少于普通B-树。由于B+树所在的磁盘存储背景下，因此B+树的查找性能要好于B-树。
2. B+树的查找效率更加稳定，因为所有叶子结点都处于同一层中，而且查找所有关键字都必须走完从根结点到叶子结点的全部历程。因此同一颗B+树中，任何关键字的查找比较次数都是一样的。而B树就不一定了，可能查找到某一个非终结点就结束了。
插入删除对比： B+树与B-树在插入删除操作中的效率是差不多的。
总体评价：在应用背景下，特别是文件结构存储中。B+树的应用要更多，其效率也要比B-树好。

### HashMap和TreeMap底层实现的不同

C++中unordered_map的底层是用哈希表来实现的，通过key的哈希路由到每一个桶（即数组）用来存放内容。通过key来获取value的时间复杂度就是O（1）。因为key的哈希容易碰撞，所以需要对碰撞做处理。unordered_map里的每一个数组（桶）里面存的其实是一个链表，key的哈希冲突以后会加到链表的尾部，这是再通过key获取value的时间复杂度就变成O(n），当碰撞很多的时候查询就会变慢。为了优化这个时间复杂度，map的底层就把这个链表转换成了红黑树，这样虽然插入增加了复杂度，但提高了频繁哈希碰撞时的查询效率，使查询效率变成O(log n)。